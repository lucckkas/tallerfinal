# ğŸ“ EvoluciÃ³n del Prompt para Sistema HAR

## ğŸ”„ IteraciÃ³n 1

### Solicitud Original

```
actua como un experto en prompt engineering y crea un buen prompt para esto: crea un modelo para HAR (human activity recognition) para el dataset MHealth (https://archive.ics.uci.edu/static/public/319/mhealth+dataset.zip) y guardalo, crea un backend y un frontend (front moderno, minimalista con estetica profesional listo para ser vendido). basate en las indicaciones de instrucciones.md
```

### âš ï¸ Problema

Faltaba especificar el split de datos y la funcionalidad de carga de archivos.

---

## ğŸ”„ IteraciÃ³n 2

### Solicitud Original

```
me falto especificar que el modelo debe ser entrenado dejando fuera a 2 personas (.log) que luego seran usados en el front para probar el sistema (el front debe poder subir archivos .log).
```

### ğŸ“‹ Respuesta del LLM

Eres un/a ML Engineer y Arquitecto/a Full-Stack Senior. Debes construir un proyecto completo, funcional de punta a punta y listo para producciÃ³n y comercializaciÃ³n. El objetivo es crear un modelo de Human Activity Recognition usando el dataset MHealth y guardarlo, ademÃ¡s de implementar un backend moderno para inferencia y un frontend moderno, minimalista y con estÃ©tica profesional listo para ser vendido. Debes basarte de forma prioritaria y estricta en el archivo instrucciones.md si estÃ¡ disponible en el contexto. Si no estÃ¡ disponible o estÃ¡ incompleto, declara explÃ­citamente los supuestos razonables que estÃ¡s haciendo y continÃºa sin bloquearte.

Usa buenas prÃ¡cticas de programaciÃ³n y mantÃ©n el cÃ³digo limpio, modular, testeable y fÃ¡cil de mantener. Evita librerÃ­as o APIs deprecadas y prioriza versiones actuales estables. Para Python usa 3.11 o superior. Para backend usa FastAPI con Pydantic v2. Para frontend usa React con Vite y TypeScript. Incluye tooling moderno de calidad como Ruff, Black, MyPy y PyTest en Python y ESLint en el frontend. Optimiza cuando sea oportuno en rendimiento, mantenibilidad y experiencia de desarrollo.

El dataset MHealth debe descargarse automÃ¡ticamente desde https://archive.ics.uci.edu/static/public/319/mhealth+dataset.zip, extraerse y parsearse. Implementa un pipeline de datos completo que incluya limpieza bÃ¡sica, segmentaciÃ³n en ventanas temporales con duraciÃ³n y solapamiento configurables, normalizaciÃ³n o estandarizaciÃ³n y una divisiÃ³n clara en train, validaciÃ³n y test. Evita fugas de datos y prioriza el split por sujeto. AdemÃ¡s, es obligatorio que el entrenamiento deje fuera a dos personas completas del dataset, identificadas por sus archivos .log, que no deben usarse ni directa ni indirectamente para entrenar, ajustar hiperparÃ¡metros o normalizadores. Esas dos personas deben quedar reservadas como un conjunto de prueba "demo" separado, pensado para validaciÃ³n final del sistema en interfaz. Debes documentar exactamente quÃ© dos sujetos fueron excluidos y por quÃ© regla se eligieron. Si instrucciones.md define cuÃ¡les son, respÃ©talo; si no lo define, elige dos sujetos de forma determinÃ­stica y explÃ­cita, y registra esa decisiÃ³n en configuraciÃ³n para que sea reproducible. Fija semillas para reproducibilidad.

Entrena al menos un baseline clÃ¡sico apropiado para series temporales transformadas a features y un modelo deep para seÃ±ales temporales, como CNN1D, GRU o una combinaciÃ³n razonable. Reporta accuracy, macro F1 y matriz de confusiÃ³n. Selecciona el mejor modelo segÃºn validaciÃ³n y guÃ¡rdalo en un formato reproducible, usando joblib si es sklearn o torch.save si es PyTorch. Debes incluir scripts separados para entrenamiento, evaluaciÃ³n e inferencia standalone. Usa configuraciÃ³n mediante .env y/o un archivo config.yaml que incluya parÃ¡metros de ventana, solapamiento, lista de sujetos excluidos para demo, rutas de artefactos y versiÃ³n del modelo.

El backend debe ser un servicio FastAPI que cargue el modelo entrenado al iniciar. ExpÃ³n endpoints GET /health, GET /model-info y POST /predict. El endpoint de predicciÃ³n debe aceptar tanto JSON con una o mÃ¡s ventanas de seÃ±ales ya preprocesadas como tambiÃ©n carga de archivos .log del formato MHealth para facilitar el flujo real. Si eliges soportar ambos modos, documenta claramente ambos contratos y provee utilidades de parsing y preprocesamiento idÃ©nticas a las usadas en entrenamiento, sin reutilizar estadÃ­sticas que incluyan a los sujetos reservados para demo. Valida entradas con Pydantic, maneja errores con mensajes claros y aÃ±ade tests bÃ¡sicos del API. Provee documentaciÃ³n de ejecuciÃ³n local y con Docker si instrucciones.md lo permite o si no hay restricciones explÃ­citas.

El frontend debe consumir el backend y ofrecer una experiencia de producto vendible. Implementa una interfaz moderna, minimalista y profesional con diseÃ±o consistente, buena tipografÃ­a y espaciado, componentes reutilizables y estados de UI bien resueltos. Debe existir una pantalla principal con explicaciÃ³n breve del producto, una secciÃ³n para probar el sistema subiendo archivos .log, incluyendo especÃ­ficamente los dos .log de las personas reservadas para demo, y un flujo alternativo para usar datos de ejemplo embebidos. Debe haber un botÃ³n para ejecutar predicciÃ³n y una visualizaciÃ³n elegante del resultado con etiqueta y confianza, ademÃ¡s de manejo de loading, error y estado vacÃ­o. Incluye en el repositorio los dos archivos .log reservados para demo o, si por tamaÃ±o no es viable, incluye archivos recortados de ejemplo representativos y un mecanismo claro para ubicarlos localmente. El objetivo es que el usuario pueda probar el sistema end-to-end desde el frontend sin reentrenar.

Organiza todo como un monorepo con carpetas separadas para ml, backend y frontend, ademÃ¡s de un README claro que explique cÃ³mo entrenar, evaluar, arrancar el API y levantar la UI. AÃ±ade configuraciÃ³n de calidad y formateo, y, si corresponde, un docker-compose para levantar backend y frontend fÃ¡cilmente. Ignora datasets pesados en git y deja solo ejemplos pequeÃ±os versionados.

Entrega tu respuesta con un resumen breve de arquitectura, luego las decisiones tÃ©cnicas justificadas, despuÃ©s un Ã¡rbol de archivos y a continuaciÃ³n el contenido completo de los archivos principales necesarios para ejecutar el proyecto. Finaliza con instrucciones de ejecuciÃ³n paso a paso, una verificaciÃ³n de calidad que cubra tests, lint y build, y una secciÃ³n de mejoras futuras opcionales. La soluciÃ³n es correcta si puedo entrenar el modelo con un comando, se genera y guarda el artefacto, el backend lo carga y predice, y el frontend permite subir .log y muestra resultados de forma elegante, usando como demo final los dos sujetos reservados que no participaron en el entrenamiento. Comienza ahora y respeta estrictamente instrucciones.md.

### âš ï¸ Problema

Demasiado complejo: mÃºltiples modelos, mÃºltiples tipos de entrada.

---

## ğŸ”„ IteraciÃ³n 3

### Solicitud Original

```
no quiero varios modelos solo uno, que sea algo que procese los datos cree las ventanas y trabaje sobre esas (no necesito un modelo que trabaje directamente sobre series de tiempo). El front solo necesita poder aceptar los .log, no necesita otro tipo de entrada (igual para el backend), lo que si me gustaria es que haya una vista de informacion del modelo (por ejemplo una matriz de confusion sobre la precision del modelo si le subo un .log con la clase target)
```

### ğŸ“‹ Respuesta del LLM

Eres un/a ML Engineer y Arquitecto/a Full-Stack Senior. Debes construir un proyecto completo, funcional de punta a punta y listo para producciÃ³n y comercializaciÃ³n. El objetivo es crear un Ãºnico modelo de Human Activity Recognition usando el dataset MHealth y guardarlo, ademÃ¡s de implementar un backend moderno para inferencia y un frontend moderno, minimalista y con estÃ©tica profesional listo para ser vendido. Debes basarte de forma prioritaria y estricta en el archivo instrucciones.md si estÃ¡ disponible en el contexto. Si no estÃ¡ disponible o estÃ¡ incompleto, declara explÃ­citamente los supuestos razonables que estÃ¡s haciendo y continÃºa sin bloquearte.

Usa buenas prÃ¡cticas de programaciÃ³n y mantÃ©n el cÃ³digo limpio, modular, testeable y fÃ¡cil de mantener. Evita librerÃ­as o APIs deprecadas y prioriza versiones actuales estables. Para Python usa 3.11 o superior. Para backend usa FastAPI con Pydantic v2. Para frontend usa React con Vite y TypeScript. Incluye tooling moderno de calidad como Ruff, Black, MyPy y PyTest en Python y ESLint en el frontend. Optimiza cuando sea oportuno en rendimiento, mantenibilidad y experiencia de desarrollo.

El dataset MHealth debe descargarse automÃ¡ticamente desde https://archive.ics.uci.edu/static/public/319/mhealth+dataset.zip, extraerse y parsearse. Implementa un pipeline de datos completo que incluya limpieza bÃ¡sica, segmentaciÃ³n en ventanas temporales con duraciÃ³n y solapamiento configurables, extracciÃ³n de caracterÃ­sticas por ventana y normalizaciÃ³n o estandarizaciÃ³n. El modelo debe trabajar sobre esas ventanas y sus features derivadas; no necesitas un modelo que opere directamente sobre series de tiempo crudas. Usa un Ãºnico algoritmo de clasificaciÃ³n adecuado para este enfoque y justifica la elecciÃ³n. La divisiÃ³n en train, validaciÃ³n y test debe evitar fugas de datos y debe priorizar split por sujeto. AdemÃ¡s, es obligatorio que el entrenamiento deje fuera a dos personas completas del dataset, identificadas por sus archivos .log, que no deben usarse ni directa ni indirectamente para entrenar, ajustar hiperparÃ¡metros ni calcular normalizadores. Esas dos personas deben quedar reservadas como un conjunto de prueba demo separado, pensado para validaciÃ³n final del sistema en interfaz. Debes documentar exactamente quÃ© dos sujetos fueron excluidos y por quÃ© regla se eligieron. Si instrucciones.md define cuÃ¡les son, respÃ©talo; si no lo define, elige dos sujetos de forma determinÃ­stica y explÃ­cita, persistiendo esa decisiÃ³n en configuraciÃ³n para que sea reproducible. Fija semillas para reproducibilidad.

Entrena ese Ãºnico modelo con el pipeline completo de ventanas y features y reporta mÃ©tricas claras como accuracy, macro F1 y matriz de confusiÃ³n sobre validaciÃ³n y test, dejando explÃ­cito el desempeÃ±o sobre el conjunto demo reservando a las dos personas excluidas. Guarda el artefacto del modelo en un formato reproducible junto con cualquier transformador necesario para que la inferencia sea idÃ©ntica al entrenamiento. Debes incluir scripts separados para entrenamiento, evaluaciÃ³n e inferencia standalone. Usa configuraciÃ³n mediante .env y/o un archivo config.yaml que incluya parÃ¡metros de ventana, solapamiento, lista de sujetos excluidos para demo, rutas de artefactos y versiÃ³n del modelo.

El backend debe ser un servicio FastAPI que cargue el modelo entrenado y sus transformadores al iniciar. El backend solo necesita aceptar archivos .log del formato MHealth, no debe ofrecer entradas alternativas como JSON de ventanas. ExpÃ³n endpoints GET /health, GET /model-info, POST /predict y un endpoint adicional para evaluaciÃ³n de un archivo etiquetado, por ejemplo POST /evaluate-log. El endpoint /predict debe recibir un .log, aplicar el mismo preprocesamiento, crear ventanas, extraer features, ejecutar inferencia y devolver una predicciÃ³n por ventana y un resumen agregado por actividad con probabilidades o confianza. El endpoint /evaluate-log debe aceptar un .log que contenga la clase target y devolver mÃ©tricas y una matriz de confusiÃ³n calculada especÃ­ficamente para ese archivo. Valida entradas, maneja errores con mensajes claros y aÃ±ade tests bÃ¡sicos del API. Provee documentaciÃ³n de ejecuciÃ³n local y con Docker si instrucciones.md lo permite o si no hay restricciones explÃ­citas.

El frontend debe consumir el backend y ofrecer una experiencia de producto vendible. Implementa una interfaz moderna, minimalista y profesional con diseÃ±o consistente, buena tipografÃ­a y espaciado y componentes reutilizables. El frontend solo necesita permitir subir archivos .log, tanto para predicciÃ³n como para evaluaciÃ³n, sin otros mÃ©todos de entrada. Debe existir una vista principal para subir un .log y obtener predicciones y un resumen entendible. Debe existir una vista de informaciÃ³n del modelo que permita subir un .log etiquetado y mostrar una matriz de confusiÃ³n y mÃ©tricas asociadas de forma elegante, ademÃ¡s de mostrar tambiÃ©n informaciÃ³n del modelo cargada desde /model-info como versiÃ³n, parÃ¡metros de ventana y mÃ©tricas globales guardadas del entrenamiento. Incluye manejo de loading, error y estado vacÃ­o. Si es posible y compatible con las reglas de tamaÃ±o del repositorio, incluye los dos .log de las personas reservadas para demo para probar el flujo end-to-end desde el frontend sin reentrenar; si no es viable, incluye instrucciones claras de dÃ³nde colocarlos localmente.

Organiza todo como un monorepo con carpetas separadas para ml, backend y frontend, ademÃ¡s de un README claro que explique cÃ³mo entrenar, evaluar, arrancar el API y levantar la UI. AÃ±ade configuraciÃ³n de calidad y formateo, y, si corresponde, un docker-compose para levantar backend y frontend fÃ¡cilmente. Ignora datasets pesados en git y deja solo ejemplos pequeÃ±os versionados.

Entrega tu respuesta con un resumen breve de arquitectura, luego las decisiones tÃ©cnicas justificadas, despuÃ©s un Ã¡rbol de archivos y a continuaciÃ³n el contenido completo de los archivos principales necesarios para ejecutar el proyecto. Finaliza con instrucciones de ejecuciÃ³n paso a paso, una verificaciÃ³n de calidad que cubra tests, lint y build, y una secciÃ³n de mejoras futuras opcionales. La soluciÃ³n es correcta si puedo entrenar el modelo con un comando, se genera y guarda el artefacto, el backend lo carga y predice recibiendo solo .log, el frontend permite subir .log y muestra resultados de forma elegante, y la vista de informaciÃ³n del modelo puede calcular y mostrar una matriz de confusiÃ³n al subir un .log etiquetado. Comienza ahora y respeta estrictamente instrucciones.md.

### Con esto se generÃ³ el siguiente contenido:

```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ config/config.yaml
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ prompts/README.md
â”œâ”€â”€ ml/
â”‚ â”œâ”€â”€ requirements.txt
â”‚ â”œâ”€â”€ train.py
â”‚ â”œâ”€â”€ evaluate.py
â”‚ â”œâ”€â”€ infer.py
â”‚ â”œâ”€â”€ artifacts/
â”‚ â”œâ”€â”€ demo_logs/README.md
â”‚ â””â”€â”€ src/mhealth/
â”‚ â”œâ”€â”€ **init**.py
â”‚ â”œâ”€â”€ config.py
â”‚ â”œâ”€â”€ constants.py
â”‚ â”œâ”€â”€ data.py
â”‚ â”œâ”€â”€ preprocess.py
â”‚ â”œâ”€â”€ modeling.py
â”‚ â”œâ”€â”€ inference.py
â”‚ â””â”€â”€ utils.py
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ Dockerfile
â”‚ â”œâ”€â”€ requirements.txt
â”‚ â”œâ”€â”€ **init**.py
â”‚ â”œâ”€â”€ app/
â”‚ â”‚ â”œâ”€â”€ **init**.py
â”‚ â”‚ â”œâ”€â”€ config.py
â”‚ â”‚ â”œâ”€â”€ main.py
â”‚ â”‚ â”œâ”€â”€ schemas.py
â”‚ â”‚ â””â”€â”€ service.py
â”‚ â””â”€â”€ tests/test_api.py
â””â”€â”€ frontend/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ tsconfig.node.json
â”œâ”€â”€ vite.config.ts
â”œâ”€â”€ .eslintrc.cjs
â”œâ”€â”€ index.html
â””â”€â”€ src/
â”œâ”€â”€ App.tsx
â”œâ”€â”€ api.ts
â”œâ”€â”€ types.ts
â”œâ”€â”€ main.tsx
â””â”€â”€ index.css
```

### âš ï¸ Problema

Interfaz poco atractiva y problemas de visualizaciÃ³n.

## ğŸ”„ IteraciÃ³n 4

### Solicitud Original

```
cambia el front, la interfaz no me parece visual mente atractiva (incluso me parece basica) ademas de errores como que mostrar las ventanas en una lista no es comodo (seria bueno algo como una linea de tiempo), el texto del accuracy y macro F1 no se ve con el fondo, la matriz no cabe en el espacio asignado y se ve mal. Mejora y corrige la interfaz para que sea algo mas profesional, moderno y vendible
```

Con eso mas cambios manuales menores (como cambiar los nombres de las actividades) se llegÃ³ a una versiÃ³n que era satisfactoria.

### âš ï¸ Problema

El modelo seguÃ­a considerando la actividad 0, que representaba perÃ­odos de transiciÃ³n o inactividad, lo que afectaba negativamente su desempeÃ±o.

## ğŸ”„ IteraciÃ³n 5

### Solicitud Original

```
Corrige el modelo para que no considere la actividad 0 en el entrenamiento y evaluacion, tanto en el backend como en el frontend (el front debe dejar de mostrar la actividad 0 en las matrices de confusion y demas).
```

Con eso se mejora significativamente el desempeÃ±o del modelo.

Luego se realizaron cambios menores a la interfaz como cambiar textos, agregar hovers, mejorar la disposiciÃ³n de algunos elementos, etc. Con eso, se llegÃ³ a la versiÃ³n final del proyecto.
